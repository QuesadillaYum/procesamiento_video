{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para más información consultar Readme.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image   # for preprocessing the images\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np    # for mathematical operations\n",
    "from keras.utils import np_utils\n",
    "from skimage.transform import resize   # for resizing images\n",
    "import cv2     # for capturing videos\n",
    "import math   # for mathematical operations\n",
    "import matplotlib.pyplot as plt    # for plotting the images\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, InputLayer, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para graficar validacion accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    \"\"\"Plots accuracy/loss for training/validation set as a function of the epochs\n",
    "        :param history: Training history of model\n",
    "        :return:\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(2)\n",
    "\n",
    "    # create accuracy sublpot\n",
    "    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
    "    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
    "    axs[0].set_ylabel(\"Accuracy\")\n",
    "    axs[0].legend(loc=\"lower right\")\n",
    "    axs[0].set_title(\"Accuracy eval\")\n",
    "\n",
    "    # create error sublpot\n",
    "    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n",
    "    axs[1].plot(history.history[\"val_loss\"], label=\"test error\")\n",
    "    axs[1].set_ylabel(\"Error\")\n",
    "    axs[1].set_xlabel(\"Epoch\")\n",
    "    axs[1].legend(loc=\"upper right\")\n",
    "    axs[1].set_title(\"Error eval\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract caracteristicas p/modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>frame0.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frame1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>frame2.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>frame3.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>frame4.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_ID  Class\n",
       "0  frame0.jpg      1\n",
       "1  frame1.jpg      0\n",
       "2  frame2.jpg      0\n",
       "3  frame3.jpg      0\n",
       "4  frame4.jpg      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data_completo.csv')# reading the csv file\n",
    "data.head()      # printing first five rows of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-24617b28b408>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.array(X)    # converting list to array\n"
     ]
    }
   ],
   "source": [
    "X = [ ]     # creating an empty array\n",
    "for img_name in data.image_ID:\n",
    "    img = plt.imread('./Labeled/' + img_name)\n",
    "    X.append(img)  # storing each image in array X\n",
    "X = np.array(X)    # converting list to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.Class\n",
    "dummy_y = np_utils.to_categorical(y)    # one hot encoding Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haciendo reshapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = []\n",
    "for i in range(0,X.shape[0]):\n",
    "    a = resize(X[i], preserve_range=True, output_shape=(224,224)).astype(int)      # reshaping to 224*224*3\n",
    "    image.append(a)\n",
    "X = np.array(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesado para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = preprocess_input(X, mode='tf')      # preprocessing the input data\n",
    "X = preprocess_input(X, data_format=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, dummy_y, test_size=0.3, random_state=42)    # preparing the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construyendo el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, InputLayer, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 10s 0us/step\n",
      "58900480/58889256 [==============================] - 10s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))    # include_top=False to remove the top layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((88, 7, 7, 512), (39, 7, 7, 512))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = base_model.predict(X_train)\n",
    "X_valid = base_model.predict(X_valid)\n",
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(88, 7*7*512)      # converting to 1-D\n",
    "X_valid = X_valid.reshape(39, 7*7*512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X_train/X_train.max()      # centering the data\n",
    "X_valid = X_valid/X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i. Building the model\n",
    "model = Sequential()\n",
    "model.add(InputLayer((7*7*512,)))    # input layer\n",
    "model.add(Dense(units=1024, activation='sigmoid')) # hidden layer\n",
    "model.add(Dense(2, activation='softmax'))    # output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 1024)              25691136  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,693,186\n",
      "Trainable params: 25,693,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii. Compiling the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 270ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3934 - val_accuracy: 0.9231\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 1s 239ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3940 - val_accuracy: 0.9231\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3947 - val_accuracy: 0.9231\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 1s 252ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3955 - val_accuracy: 0.9231\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3962 - val_accuracy: 0.9231\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3970 - val_accuracy: 0.9231\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 1s 231ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3978 - val_accuracy: 0.9231\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3985 - val_accuracy: 0.9231\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3993 - val_accuracy: 0.9231\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 1s 189ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4001 - val_accuracy: 0.9231\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4006 - val_accuracy: 0.9231\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4011 - val_accuracy: 0.9231\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4020 - val_accuracy: 0.9231\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 1s 232ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4025 - val_accuracy: 0.9231\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4029 - val_accuracy: 0.9231\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4035 - val_accuracy: 0.9231\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4039 - val_accuracy: 0.9231\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4046 - val_accuracy: 0.9231\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4051 - val_accuracy: 0.9231\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4057 - val_accuracy: 0.9231\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4063 - val_accuracy: 0.9231\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 1s 232ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4068 - val_accuracy: 0.9231\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4074 - val_accuracy: 0.9231\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 9.9794e-04 - accuracy: 1.0000 - val_loss: 0.4080 - val_accuracy: 0.9231\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 9.8258e-04 - accuracy: 1.0000 - val_loss: 0.4084 - val_accuracy: 0.9231\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 9.7328e-04 - accuracy: 1.0000 - val_loss: 0.4089 - val_accuracy: 0.9231\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 9.5790e-04 - accuracy: 1.0000 - val_loss: 0.4094 - val_accuracy: 0.9231\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 9.4497e-04 - accuracy: 1.0000 - val_loss: 0.4100 - val_accuracy: 0.9231\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 9.3367e-04 - accuracy: 1.0000 - val_loss: 0.4105 - val_accuracy: 0.9231\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 9.1837e-04 - accuracy: 1.0000 - val_loss: 0.4111 - val_accuracy: 0.9231\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 9.0922e-04 - accuracy: 1.0000 - val_loss: 0.4117 - val_accuracy: 0.9231\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 8.9453e-04 - accuracy: 1.0000 - val_loss: 0.4122 - val_accuracy: 0.9231\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 1s 262ms/step - loss: 8.8299e-04 - accuracy: 1.0000 - val_loss: 0.4130 - val_accuracy: 0.9231\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 1s 300ms/step - loss: 8.7106e-04 - accuracy: 1.0000 - val_loss: 0.4136 - val_accuracy: 0.9231\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 1s 245ms/step - loss: 8.5798e-04 - accuracy: 1.0000 - val_loss: 0.4141 - val_accuracy: 0.9231\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 8.4797e-04 - accuracy: 1.0000 - val_loss: 0.4147 - val_accuracy: 0.9231\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 1s 198ms/step - loss: 8.3898e-04 - accuracy: 1.0000 - val_loss: 0.4153 - val_accuracy: 0.9231\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 8.2871e-04 - accuracy: 1.0000 - val_loss: 0.4157 - val_accuracy: 0.9231\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 8.1829e-04 - accuracy: 1.0000 - val_loss: 0.4161 - val_accuracy: 0.9231\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 8.0817e-04 - accuracy: 1.0000 - val_loss: 0.4165 - val_accuracy: 0.9231\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 8.0125e-04 - accuracy: 1.0000 - val_loss: 0.4168 - val_accuracy: 0.9231\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 7.9085e-04 - accuracy: 1.0000 - val_loss: 0.4171 - val_accuracy: 0.9231\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 1s 196ms/step - loss: 7.8011e-04 - accuracy: 1.0000 - val_loss: 0.4174 - val_accuracy: 0.9231\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 7.6837e-04 - accuracy: 1.0000 - val_loss: 0.4179 - val_accuracy: 0.9231\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 7.5980e-04 - accuracy: 1.0000 - val_loss: 0.4185 - val_accuracy: 0.9231\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 7.4903e-04 - accuracy: 1.0000 - val_loss: 0.4191 - val_accuracy: 0.9231\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 7.4195e-04 - accuracy: 1.0000 - val_loss: 0.4199 - val_accuracy: 0.9231\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 1s 200ms/step - loss: 7.3380e-04 - accuracy: 1.0000 - val_loss: 0.4204 - val_accuracy: 0.9231\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 7.2618e-04 - accuracy: 1.0000 - val_loss: 0.4210 - val_accuracy: 0.9231\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 7.1624e-04 - accuracy: 1.0000 - val_loss: 0.4215 - val_accuracy: 0.9231\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 1s 243ms/step - loss: 7.0860e-04 - accuracy: 1.0000 - val_loss: 0.4219 - val_accuracy: 0.9231\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 7.0074e-04 - accuracy: 1.0000 - val_loss: 0.4224 - val_accuracy: 0.9231\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 6.9225e-04 - accuracy: 1.0000 - val_loss: 0.4228 - val_accuracy: 0.9231\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 6.8375e-04 - accuracy: 1.0000 - val_loss: 0.4233 - val_accuracy: 0.9231\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 6.7730e-04 - accuracy: 1.0000 - val_loss: 0.4237 - val_accuracy: 0.9231\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 1s 199ms/step - loss: 6.6706e-04 - accuracy: 1.0000 - val_loss: 0.4241 - val_accuracy: 0.9231\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 6.5911e-04 - accuracy: 1.0000 - val_loss: 0.4246 - val_accuracy: 0.9231\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 6.5284e-04 - accuracy: 1.0000 - val_loss: 0.4251 - val_accuracy: 0.9231\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 6.4550e-04 - accuracy: 1.0000 - val_loss: 0.4255 - val_accuracy: 0.9231\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 6.3915e-04 - accuracy: 1.0000 - val_loss: 0.4260 - val_accuracy: 0.9231\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 6.3174e-04 - accuracy: 1.0000 - val_loss: 0.4265 - val_accuracy: 0.9231\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 6.2593e-04 - accuracy: 1.0000 - val_loss: 0.4268 - val_accuracy: 0.9231\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 6.2027e-04 - accuracy: 1.0000 - val_loss: 0.4271 - val_accuracy: 0.9231\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 6.1277e-04 - accuracy: 1.0000 - val_loss: 0.4276 - val_accuracy: 0.9231\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 1s 200ms/step - loss: 6.0588e-04 - accuracy: 1.0000 - val_loss: 0.4282 - val_accuracy: 0.9231\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 5.9907e-04 - accuracy: 1.0000 - val_loss: 0.4286 - val_accuracy: 0.9231\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 5.9204e-04 - accuracy: 1.0000 - val_loss: 0.4291 - val_accuracy: 0.9231\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 5.8807e-04 - accuracy: 1.0000 - val_loss: 0.4296 - val_accuracy: 0.9231\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 5.8019e-04 - accuracy: 1.0000 - val_loss: 0.4300 - val_accuracy: 0.9231\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 5.7515e-04 - accuracy: 1.0000 - val_loss: 0.4304 - val_accuracy: 0.9231\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 5.6826e-04 - accuracy: 1.0000 - val_loss: 0.4309 - val_accuracy: 0.9231\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 5.6264e-04 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.9231\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 1s 197ms/step - loss: 5.5665e-04 - accuracy: 1.0000 - val_loss: 0.4318 - val_accuracy: 0.9231\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 5.5082e-04 - accuracy: 1.0000 - val_loss: 0.4321 - val_accuracy: 0.9231\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 5.4546e-04 - accuracy: 1.0000 - val_loss: 0.4327 - val_accuracy: 0.9231\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 5.3942e-04 - accuracy: 1.0000 - val_loss: 0.4332 - val_accuracy: 0.9231\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 5.3384e-04 - accuracy: 1.0000 - val_loss: 0.4336 - val_accuracy: 0.9231\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 5.2843e-04 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.9231\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 5.2266e-04 - accuracy: 1.0000 - val_loss: 0.4345 - val_accuracy: 0.9231\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 5.1904e-04 - accuracy: 1.0000 - val_loss: 0.4348 - val_accuracy: 0.9231\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 5.1315e-04 - accuracy: 1.0000 - val_loss: 0.4353 - val_accuracy: 0.9231\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 5.0941e-04 - accuracy: 1.0000 - val_loss: 0.4358 - val_accuracy: 0.9231\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 5.0303e-04 - accuracy: 1.0000 - val_loss: 0.4362 - val_accuracy: 0.9231\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 1s 200ms/step - loss: 4.9820e-04 - accuracy: 1.0000 - val_loss: 0.4367 - val_accuracy: 0.9231\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 4.9422e-04 - accuracy: 1.0000 - val_loss: 0.4372 - val_accuracy: 0.9231\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 4.8940e-04 - accuracy: 1.0000 - val_loss: 0.4375 - val_accuracy: 0.9231\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 4.8484e-04 - accuracy: 1.0000 - val_loss: 0.4380 - val_accuracy: 0.9231\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 4.7938e-04 - accuracy: 1.0000 - val_loss: 0.4383 - val_accuracy: 0.9231\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 4.7559e-04 - accuracy: 1.0000 - val_loss: 0.4387 - val_accuracy: 0.9231\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 4.7025e-04 - accuracy: 1.0000 - val_loss: 0.4390 - val_accuracy: 0.9231\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 4.6811e-04 - accuracy: 1.0000 - val_loss: 0.4395 - val_accuracy: 0.9231\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 4.6243e-04 - accuracy: 1.0000 - val_loss: 0.4400 - val_accuracy: 0.9231\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 4.5894e-04 - accuracy: 1.0000 - val_loss: 0.4404 - val_accuracy: 0.9231\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 4.5394e-04 - accuracy: 1.0000 - val_loss: 0.4407 - val_accuracy: 0.9231\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 4.4966e-04 - accuracy: 1.0000 - val_loss: 0.4411 - val_accuracy: 0.9231\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 4.4552e-04 - accuracy: 1.0000 - val_loss: 0.4414 - val_accuracy: 0.9231\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 1s 237ms/step - loss: 4.4243e-04 - accuracy: 1.0000 - val_loss: 0.4417 - val_accuracy: 0.9231\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 4.3727e-04 - accuracy: 1.0000 - val_loss: 0.4421 - val_accuracy: 0.9231\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 4.3343e-04 - accuracy: 1.0000 - val_loss: 0.4425 - val_accuracy: 0.9231\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 1s 198ms/step - loss: 4.2947e-04 - accuracy: 1.0000 - val_loss: 0.4427 - val_accuracy: 0.9231\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# iii. Training the model\n",
    "history=model.fit(train, y_train, epochs=100, validation_data=(X_valid, y_valid))\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba con videos en ambos estados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extrayendo las frames del video prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "videoFile = \"./Raw/Ambos_test/VID_20220202_155903.mp4\"\n",
    "cap = cv2.VideoCapture(videoFile)\n",
    "frameRate = cap.get(5) #frame rate\n",
    "x=1\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename =\"test%d.jpg\" % count;count+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "cap.release()\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vid. 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_name = ['image_ID']\n",
    "list0=[[\"test0.jpg\"],\n",
    "      [\"test1.jpg\"],\n",
    "      [\"test2.jpg\"],\n",
    "      [\"test3.jpg\"],\n",
    "      [\"test4.jpg\"],\n",
    "      [\"test5.jpg\"],\n",
    "      [\"test6.jpg\"],\n",
    "      [\"test7.jpg\"],\n",
    "      [\"test8.jpg\"],\n",
    "      [\"test9.jpg\"],\n",
    "      [\"test10.jpg\"],\n",
    "      [\"test11.jpg\"],\n",
    "      [\"test12.jpg\"]\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test7.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test8.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test9.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test11.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>test12.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_ID\n",
       "0    test0.jpg\n",
       "1    test1.jpg\n",
       "2    test2.jpg\n",
       "3    test3.jpg\n",
       "4    test4.jpg\n",
       "5    test5.jpg\n",
       "6    test6.jpg\n",
       "7    test7.jpg\n",
       "8    test8.jpg\n",
       "9    test9.jpg\n",
       "10  test10.jpg\n",
       "11  test11.jpg\n",
       "12  test12.jpg"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(list0,columns=cols_name)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test4.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_ID\n",
       "0  test0.jpg\n",
       "1  test1.jpg\n",
       "2  test2.jpg\n",
       "3  test3.jpg\n",
       "4  test4.jpg"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=pd.read_csv(\"test.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = []\n",
    "for img_name in test.image_ID:\n",
    "    img = plt.imread('' + img_name)\n",
    "    test_image.append(img)\n",
    "test_img = np.array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 1080, 1920, 3)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image0 = []\n",
    "for i in range(0,test_img.shape[0]):\n",
    "    a = resize(test_img[i], preserve_range=True, output_shape=(224,224)).astype(int)\n",
    "    test_image0.append(a)\n",
    "test_image = np.array(test_image0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 224, 224, 3)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the images\n",
    "test_image = preprocess_input(test_image, data_format=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting features from the images using pretrained model\n",
    "test_image = base_model.predict(test_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 7, 7, 512)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the images to 1-D form\n",
    "test_image = test_image.reshape(13, 7*7*512)\n",
    "\n",
    "# zero centered images\n",
    "test_image = test_image/test_image.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=np.argmax(predictions,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The screen time of Sleep is 7 seconds\n",
      "The screen time of Wake is 6 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"El tiempo/frames en pantalla dormido es de\", predictions[predictions==0].shape[0], \"seconds\")\n",
    "print(\"El tiempo/frames en pantalla despierto es de\", predictions[predictions==1].shape[0], \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Participante Mi.\n",
    "De los 11 segundos se extrajeron 13 fotogramas, de los cuales 7 corresponden a dormidos y 6 despiertos, como el modelo predijo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vid. 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "videoFile = \"./Raw/Ambos_test/VID-20220203-WA0050.mp4\"\n",
    "cap = cv2.VideoCapture(videoFile)\n",
    "frameRate = cap.get(5) #frame rate\n",
    "x=1\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename =\"test%d.jpg\" % count;count+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "cap.release()\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_name = ['image_ID']\n",
    "list0=[[\"test0.jpg\"],\n",
    "      [\"test1.jpg\"],\n",
    "      [\"test2.jpg\"],\n",
    "      [\"test3.jpg\"],\n",
    "      [\"test4.jpg\"],\n",
    "      [\"test5.jpg\"],\n",
    "      [\"test6.jpg\"],\n",
    "      [\"test7.jpg\"],\n",
    "      [\"test8.jpg\"],\n",
    "      [\"test9.jpg\"],\n",
    "      [\"test10.jpg\"],\n",
    "      [\"test11.jpg\"],\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test7.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test8.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test9.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test11.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_ID\n",
       "0    test0.jpg\n",
       "1    test1.jpg\n",
       "2    test2.jpg\n",
       "3    test3.jpg\n",
       "4    test4.jpg\n",
       "5    test5.jpg\n",
       "6    test6.jpg\n",
       "7    test7.jpg\n",
       "8    test8.jpg\n",
       "9    test9.jpg\n",
       "10  test10.jpg\n",
       "11  test11.jpg"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(list0,columns=cols_name)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test4.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_ID\n",
       "0  test0.jpg\n",
       "1  test1.jpg\n",
       "2  test2.jpg\n",
       "3  test3.jpg\n",
       "4  test4.jpg"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=pd.read_csv(\"test1.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = []\n",
    "for img_name in test.image_ID:\n",
    "    img = plt.imread('' + img_name)\n",
    "    test_image.append(img)\n",
    "test_img = np.array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image0 = []\n",
    "for i in range(0,test_img.shape[0]):\n",
    "    a = resize(test_img[i], preserve_range=True, output_shape=(224,224)).astype(int)\n",
    "    test_image0.append(a)\n",
    "test_image = np.array(test_image0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the images\n",
    "test_image = preprocess_input(test_image, data_format=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting features from the images using pretrained model\n",
    "test_image = base_model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 7, 7, 512)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the images to 1-D form\n",
    "test_image = test_image.reshape(12, 7*7*512)\n",
    "\n",
    "# zero centered images\n",
    "test_image = test_image/test_image.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=np.argmax(predictions,axis=1) #Redondea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tiempo en pantalla dormido es de 5 seconds\n",
      "El tiempo en pantalla despierto es de 7 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"El tiempo/frames en pantalla dormido es de\", predictions[predictions==0].shape[0], \"seconds\")\n",
    "print(\"El tiempo/frames en pantalla despierto es de\", predictions[predictions==1].shape[0], \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Participante D, de los 11 segundos del video se extrajeron 12 frames de los cuales 6 eran dormidos y 6 despiertos. Por lo cual el modelo obtuvo un falso negativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.981243405884882"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frameRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "41dbb3ea2c53b2d1632921de81f0ef81210443aa957bb432b85b26327cc304c9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
